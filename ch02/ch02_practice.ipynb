{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e64f638-fa34-4ef7-a0ae-e4f3c3f62656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index==0.11.11 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d511edf9-6b4d-4e7f-88b4-f6829dd72cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting docx2txt\n",
      "  Downloading docx2txt-0.9-py3-none-any.whl.metadata (529 bytes)\n",
      "Downloading docx2txt-0.9-py3-none-any.whl (4.0 kB)\n",
      "Installing collected packages: docx2txt\n",
      "Successfully installed docx2txt-0.9\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install docx2txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca605ea-5889-4362-a99f-428cd0f0f349",
   "metadata": {},
   "source": [
    "## 2.2 데이터 로딩"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4d8a9e-1d9d-4f4e-a1a2-ea3ea9d87fe2",
   "metadata": {},
   "source": [
    "### 2.2.1 데이터 리더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52e12c8c-a9c1-467d-83f9-5075eb69dfa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 6 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "documents = SimpleDirectoryReader(\"sample_docs\").load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68b5a7cf-da7a-4f49-a8f7-1f364f82e688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "This is the content of file 1.\n",
      "\n",
      "\n",
      "Document 2:\n",
      "This is the content of file 2.\n",
      "\n",
      "\n",
      "Document 3:\n",
      "This is the content of ﬁle 3. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Document 리스트의 각 요소에 접근하여 내용 출력\n",
    "for i, document in enumerate(documents):\n",
    "    print(f\"Document {i+1}:\")\n",
    "    print(document.text)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9c2ef93-2743-4f6c-84a8-1577b9d993e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 6 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "documents = SimpleDirectoryReader(\n",
    "    \"sample_docs\", recursive=True).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "592bdffb-8901-4244-8d02-385fa979e056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "This is the content of file 1.\n",
      "\n",
      "\n",
      "Document 2:\n",
      "This is the content of file 2.\n",
      "\n",
      "\n",
      "Document 3:\n",
      "This is the content of ﬁle 3. \n",
      "\n",
      "\n",
      "Document 4:\n",
      "This is the content of file 4.\n",
      "\n",
      "\n",
      "Document 5:\n",
      "This is the content of file 5.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Document 리스트의 각 요소에 접근하여 내용 출력\n",
    "for i, document in enumerate(documents):\n",
    "    print(f\"Document {i+1}:\")\n",
    "    print(document.text)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "085eea22-bf75-4d39-bf44-85f7588b137c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ignoring wrong pointing object 6 0 (offset 0)\n"
     ]
    }
   ],
   "source": [
    "documents = SimpleDirectoryReader(\n",
    "    \"sample_docs\",\n",
    "    required_exts=[\".txt\", \".pdf\"],\n",
    "    recursive=True).load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fd589fcd-bafb-456e-9c45-a2190a2e070b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "This is the content of file 1.\n",
      "\n",
      "\n",
      "Document 2:\n",
      "This is the content of ﬁle 3. \n",
      "\n",
      "\n",
      "Document 3:\n",
      "This is the content of file 4.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Document 리스트의 각 요소에 접근하여 내용 출력\n",
    "for i, document in enumerate(documents):\n",
    "    print(f\"Document {i+1}:\")\n",
    "    print(document.text)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29a7554c-8a98-47cf-aa07-eb1e191efc7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1 metadata:\n",
      "{'file_path': '/external/llama-index-tutorial/ch02/sample_docs/file1.txt', 'file_name': 'file1.txt', 'file_type': 'text/plain', 'file_size': 30, 'creation_date': '2025-07-04', 'last_modified_date': '2025-07-04'}\n",
      "\n",
      "\n",
      "Document 2 metadata:\n",
      "{'page_label': '1', 'file_name': 'file3.pdf', 'file_path': '/external/llama-index-tutorial/ch02/sample_docs/file3.pdf', 'file_type': 'application/pdf', 'file_size': 9283, 'creation_date': '2025-07-04', 'last_modified_date': '2025-07-04'}\n",
      "\n",
      "\n",
      "Document 3 metadata:\n",
      "{'file_path': '/external/llama-index-tutorial/ch02/sample_docs/sub_sample_docs/file4.txt', 'file_name': 'file4.txt', 'file_type': 'text/plain', 'file_size': 30, 'creation_date': '2025-07-04', 'last_modified_date': '2025-07-04'}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# document 리스트의 각 요소에 접근하여 메타데이터를 출력\n",
    "for i, document in enumerate(documents):\n",
    "    print(f\"Document {i+1} metadata:\")\n",
    "    print(document.metadata)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9a7247-09a8-4d1b-8713-d735e99491a5",
   "metadata": {},
   "source": [
    "### 2.2.2 데이터 커넥터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cc393c4f-234e-47f1-9b76-573cc05c00da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-index-readers-database==0.3.0 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9ed0e00-2c38-4383-8b74-84d88071868d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymysql\n",
      "  Downloading PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)\n",
      "Downloading PyMySQL-1.1.1-py3-none-any.whl (44 kB)\n",
      "Installing collected packages: pymysql\n",
      "Successfully installed pymysql-1.1.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe2a5d64-18d1-49fe-be66-4033eda09c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from llama_index.readers.database import DatabaseReader\n",
    "\n",
    "# MySQL 연결 정보 직접 입력\n",
    "scheme = \"mysql+pymysql\"\n",
    "host = \"localhost\"\n",
    "password = \"!23\"\n",
    "port = \"3306\"\n",
    "user = \"root\"\n",
    "dbname = \"test_db\"\n",
    "\n",
    "connection_string = f\"{scheme}://{user}:{password}@{host}:{port}/{dbname}\"\n",
    "engine = create_engine(connection_string)\n",
    "reader = DatabaseReader(sql_database=engine)\n",
    "\n",
    "# 데이터 로드\n",
    "query = \"SELECT * FROM users\"\n",
    "documents = reader.load_data(query=query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a5e2bd99-92a7-4b80-b46c-73300a8a8a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 1:\n",
      "ID 26ac5d69-f2a0-4774-b8db-7f44e8ddaf5a\n",
      "Row id: 1, name: Alice, email: alice@example.com, age: 30\n",
      "--------------------------------------------------\n",
      "Document 2:\n",
      "ID f5d575a4-1170-404b-985a-cefa40909b6a\n",
      "Row id: 2, name: Bob, email: bob@example.com, age: 25\n",
      "--------------------------------------------------\n",
      "Document 3:\n",
      "ID e98158f4-09ed-4979-9b3f-85e5db629004\n",
      "Row id: 3, name: Charlie, email: charlie@example.com, age: 35\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# documents 리스트의 각 요소 출력\n",
    "for idx, doc in enumerate(documents):\n",
    "    print(f\"Document {idx + 1}:\")\n",
    "    print(f\"ID {doc.id_}\")\n",
    "    print(f\"Row {doc.text}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74cbcce-07df-441c-8561-4fb69c826997",
   "metadata": {},
   "source": [
    "## 2.3 텍스트 분할"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef50fea-7d89-4535-8395-265c308d2e20",
   "metadata": {},
   "source": [
    "### 2.3.1 문서와 노드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "262db416-1ab1-4d21-aff3-bfc9ba6769b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc ID: 77c3f790-2236-4789-97b3-09ec2ef10841\n",
      "Text: 영화 '기생충'은 가난한 가족인 기우네가 부유한 박 사장네 집에 하나씩 취업하면서 벌어지는 이야기입니다. 처음에는\n",
      "평화로워 보이지만, 이들의 거짓말이 쌓이며 긴장감이 점점 고조됩니다. 박 사장네 집에는 비밀 지하실이 존재하며, 그곳에는\n",
      "오랫동안 숨어 살던 남자가 있다는 반전이 있습니다. 이 사실을 알게 된 기우네 가족은 예상치 못한 위기를 맞이하게 됩니다.\n",
      "결국 극한 상황에서 벌어지는 사건으로 인해 비극적인 결말로 이어집니다.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import Document\n",
    "\n",
    "# 텍스트 데이터를 기반으로 문서 생성\n",
    "document_text = \"영화 '기생충'은 가난한 가족인 기우네가 부유한 박 사장네 집에 하나씩 취업하면서 벌어지는 이야기입니다. 처음에는 평화로워 보이지만, 이들의 거짓말이 쌓이며 긴장감이 점점 고조됩니다. 박 사장네 집에는 비밀 지하실이 존재하며, 그곳에는 오랫동안 숨어 살던 남자가 있다는 반전이 있습니다. 이 사실을 알게 된 기우네 가족은 예상치 못한 위기를 맞이하게 됩니다. 결국 극한 상황에서 벌어지는 사건으로 인해 비극적인 결말로 이어집니다.\"\n",
    "document = Document(text=document_text)\n",
    "\n",
    "# 메타데이터 추가\n",
    "document.metadata = {'author': '영화 해설', 'subject': '기생충 줄거리'}\n",
    "\n",
    "print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e04ceb2-43b3-455a-a8de-5017523baf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "생성된 노드들\n",
      "노드 1: 영화 '기생충'은 가난한 가족인 기우네가 부유한 박 사장네 집에 하나씩 취업하면서 벌어지는 이야기입니다.\n",
      "   메타데이터: {'type': '영화 줄거리', 'genre': '드라마', 'node_id': 1}\n",
      "노드 2: 처음에는 평화로워 보이지만, 이들의 거짓말이 쌓이며 긴장감이 점점 고조됩니다.\n",
      "   메타데이터: {'type': '영화 줄거리', 'genre': '드라마', 'node_id': 2}\n",
      "노드 3: 박 사장네 집에는 비밀 지하실이 존재하며, 그곳에는 오랫동안 숨어 살던 남자가 있다는 반전이 있습니다.\n",
      "   메타데이터: {'type': '영화 줄거리', 'genre': '드라마', 'node_id': 3}\n",
      "노드 4: 이 사실을 알게 된 기우네 가족은 예상치 못한 위기를 맞이하게 됩니다.\n",
      "   메타데이터: {'type': '영화 줄거리', 'genre': '드라마', 'node_id': 4}\n",
      "노드 5: 결국 극한 상황에서 벌어지는 사건으로 인해 비극적인 결말로 이어집니다.\n",
      "   메타데이터: {'type': '영화 줄거리', 'genre': '드라마', 'node_id': 5}\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "\n",
    "parser = SimpleNodeParser(chunk_size=80, chunk_overlap=0)\n",
    "nodes = parser.get_nodes_from_documents([document])\n",
    "\n",
    "print(\"\\n생성된 노드들\")\n",
    "for idx, node in enumerate(nodes, start=1):\n",
    "    node.metadata = {'type': '영화 줄거리', 'genre': '드라마', 'node_id': idx}\n",
    "    print(f\"노드 {idx}: {node.text}\")\n",
    "    print(f\"   메타데이터: {node.metadata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ad20f75-422a-43e4-afb3-eda1a6839406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "청크 1: 영화 '기생충'은 가난한 가족인 기우네가 부유한 박 사장네 집에 하나씩 취업하면서 벌어지는 이야기입니다. 처음에는 평화로워 보이지만, 이들의\n",
      "[토큰 개수: 77]\n",
      "\n",
      "청크 2: 거짓말이 쌓이며 긴장감이 점점 고조됩니다. 박 사장네 집에는 비밀 지하실이 존재하며, 그곳에는 오랫동안 숨어 살던 남자가 있다는\n",
      "[토큰 개수: 78]\n",
      "\n",
      "청크 3: 반전이 있습니다. 이 사실을 알게 된 기우네 가족은 예상치 못한 위기를 맞이하게 됩니다. 결국 극한 상황에서 벌어지는 사건으로 인해 비극적인 결말로 이어집니다.\n",
      "[토큰 개수: 80]\n",
      "\n",
      "총 생성된 청크 개수: 3\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.node_parser import TokenTextSplitter\n",
    "import tiktoken\n",
    "\n",
    "# cl100k_base 토크나이저 로드\n",
    "tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "token_splitter = TokenTextSplitter(chunk_size=80, chunk_overlap=0)\n",
    "\n",
    "chunks = token_splitter.split_text(document_text)\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    token_count = len(tokenizer.encode(chunk))  # 각 청크의 토큰 개수 계산\n",
    "    print(f\"청크 {i+1}: {chunk}\\n[토큰 개수: {token_count}]\\n\")\n",
    "\n",
    "print(f\"총 생성된 청크 개수: {len(chunks)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72026578-0a3f-48ba-9b1e-01e6a9fe3728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "문서 단위 검색 결과\n",
      "문서 검색 응답: 이 영화의 반전은 박 사장네 집에 숨어 살던 남자가 존재한다는 사실입니다.\n",
      "- 결과 1: 영화 '기생충'은 가난한 가족인 기우네가 부유한 박 사장네 집에 하나씩 취업하면서 벌어지는 이야기입니다. 처음에는 평화로워 보이지만, 이들의 거짓말이 쌓이며 긴장감이 점점 고조됩니다. 박 사장네 집에는 비밀 지하실이 존재하며, 그곳에는 오랫동안 숨어 살던 남자가 있다는 반전이 있습니다. 이 사실을 알게 된 기우네 가족은 예상치 못한 위기를 맞이하게 됩니다. 결국 극한 상황에서 벌어지는 사건으로 인해 비극적인 결말로 이어집니다.\n",
      "\n",
      "노드 단위 검색 결과\n",
      "노드 검색 응답: 남자가 박 사장네 집의 비밀 지하실에 숨어 살고 있다는 반전입니다.\n",
      "- 결과 노드 1: 박 사장네 집에는 비밀 지하실이 존재하며, 그곳에는 오랫동안 숨어 살던 남자가 있다는 반전이 있습니다.\n",
      "- 결과 노드 2: 결국 극한 상황에서 벌어지는 사건으로 인해 비극적인 결말로 이어집니다.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import VectorStoreIndex, Document, Settings\n",
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "from llama_index.llms.openai import OpenAI\n",
    "\n",
    "# 한글 답변 설정\n",
    "llm = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"], model=\"gpt-4o-mini\", system_prompt=\"반드시 한국어로 답변하세요.\")\n",
    "# Settings.llm = OpenAI(model=\"gpt-4o-mini\", temperature=0, system_prompt=\"항상 한국어로 답변하세요.\")\n",
    "\n",
    "# 문서 단위 검색을 위한 전체 문서 인덱스 생성\n",
    "full_doc_index = VectorStoreIndex.from_documents([document], llm=llm)\n",
    "\n",
    "# NodeParser를 사용하여 문서를 작은 의미 단위(Node)로 분할\n",
    "# parser = SimpleNodeParser(chunk_size=100, chunk_overlap=0)\n",
    "# nodes = parser.get_nodes_from_documents([document])\n",
    "\n",
    "# 노드 단위 검색을 위한 인덱스 생성\n",
    "node_index = VectorStoreIndex(nodes, llm=llm)\n",
    "\n",
    "# 검색 비교\n",
    "query_text = '이 영화의 반전은 무엇인가요?'\n",
    "\n",
    "## 문서 단위 검색\n",
    "print(\"\\n문서 단위 검색 결과\")\n",
    "doc_query_engine = full_doc_index.as_query_engine()\n",
    "doc_response = doc_query_engine.query(query_text)\n",
    "print(f\"문서 검색 응답: {doc_response.response}\")\n",
    "if doc_response.source_nodes:\n",
    "    for idx, document in enumerate(doc_response.source_nodes, start=1):\n",
    "        print(f\"- 결과 {idx}: {document.node.text}\")\n",
    "\n",
    "## 노드 단위 검색\n",
    "print(\"\\n노드 단위 검색 결과\")\n",
    "node_query_engine = node_index.as_query_engine()\n",
    "node_response = node_query_engine.query(query_text)\n",
    "print(f\"노드 검색 응답: {node_response.response}\")\n",
    "if node_response.source_nodes:\n",
    "    for idx, document in enumerate(node_response.source_nodes, start=1):\n",
    "        print(f\"- 결과 노드 {idx}: {document.node.text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e408b1-6994-4563-95a0-32baaff5ac27",
   "metadata": {},
   "source": [
    "### 2.3.2 토큰 단위 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a958acee-d24e-46a3-83f4-ad697a091662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 토큰 기반 분할 결과 ===\n",
      "Chunk 1: 영화 '기생충'은 가난한 가족인 기우네가 부유한 박 사장네 집에 하나씩 취업하면서 \n",
      "\n",
      "Chunk 2: 취업하면서 벌어지는 이야기입니다. 처음에는 평화로워 보이지만, 이들의 거짓말이 쌓이며 \n",
      "\n",
      "Chunk 3: 쌓이며 긴장감이 점점 고조됩니다. 그러나 이 영화의 반전은 지하실에서 시작됩니다. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"영화 '기생충'은 가난한 가족인 기우네가 부유한 박 사장네 집에 하나씩 취업하면서 벌어지는 이야기입니다. 처음에는 평화로워 보이지만, 이들의 거짓말이 쌓이며 긴장감이 점점 고조됩니다. 그러나 이 영화의 반전은 지하실에서 시작됩니다.\"\n",
    "\n",
    "\n",
    "token_splitter = TokenTextSplitter(\n",
    "    chunk_size=50,\n",
    "    chunk_overlap=10\n",
    ")\n",
    "\n",
    "token_chunks = token_splitter.split_text(sample_text)\n",
    "print(\"=== 토큰 기반 분할 결과 ===\")\n",
    "for i, chunk in enumerate(token_chunks):\n",
    "    print(f\"Chunk {i + 1}:\", chunk.strip(), \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e6fdf1-894d-42e9-b966-a8d18da837b2",
   "metadata": {},
   "source": [
    "### 2.3.3 문장 단위 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9304545-4be1-4048-b9f1-dfbde66f32b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 문장 기반 분할 결과 ===\n",
      "Chunk 1: 영화 '기생충'은 가난한 가족인 기우네가 부유한 박 사장네 집에 하나씩 취업하면서 \n",
      "\n",
      "Chunk 2: 벌어지는 이야기입니다. \n",
      "\n",
      "Chunk 3: 처음에는 평화로워 보이지만, 이들의 거짓말이 쌓이며 긴장감이 점점 고조됩니다. \n",
      "\n",
      "Chunk 4: 그러나 이 영화의 반전은 지하실에서 시작됩니다. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.node_parser.text.sentence import SentenceSplitter\n",
    "\n",
    "splitter = SentenceSplitter(chunk_size=50, chunk_overlap=0)\n",
    "\n",
    "sentence_chunks = splitter.split_text(sample_text)\n",
    "print(\"=== 문장 기반 분할 결과 ===\")\n",
    "for i, chunk in enumerate(sentence_chunks):\n",
    "    print(f\"Chunk {i + 1}:\", chunk.strip(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b241315-b062-4ac8-a4d2-dceac7c4f98a",
   "metadata": {},
   "source": [
    "### 2.3.4 의미 단위 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d80a240-dcdb-4c6c-b7b3-d946ed2e8183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 의미 기반 분할 결과 ===\n",
      "Chunk 1: 영화 '기생충'은 가난한 가족인 기우네가 부유한 박 사장네 집에 하나씩 취업하면서 벌어지는 이야기입니다. \n",
      "\n",
      "Chunk 2: 처음에는 평화로워 보이지만, 이들의 거짓말이 쌓이며 긴장감이 점점 고조됩니다. \n",
      "\n",
      "Chunk 3: 그러나 이 영화의 반전은 지하실에서 시작됩니다. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.node_parser import SemanticSplitterNodeParser\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "embed_model = OpenAIEmbedding()\n",
    "\n",
    "splitter = SemanticSplitterNodeParser(\n",
    "    buffer_size=1,\n",
    "    breakpoint_percentile_threshold=95,\n",
    "    embed_model=embed_model\n",
    ")\n",
    "\n",
    "chunks = splitter.sentence_splitter(sample_text)\n",
    "print(\"=== 의미 기반 분할 결과 ===\")\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i + 1}:\", chunk.strip(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83f3ce71-5ae0-4b03-bf3d-82efa56faeac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers -q\n",
    "!pip install llama-index-embeddings-huggingface -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e03d8b04-1173-49b0-9fb9-4ce97a5e22b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 의미 기반 분할 결과 ===\n",
      "Chunk 1: 영화 '기생충'은 가난한 가족인 기우네가 부유한 박 사장네 집에 하나씩 취업하면서 벌어지는 이야기입니다. \n",
      "\n",
      "Chunk 2: 처음에는 평화로워 보이지만, 이들의 거짓말이 쌓이며 긴장감이 점점 고조됩니다. \n",
      "\n",
      "Chunk 3: 그러나 이 영화의 반전은 지하실에서 시작됩니다. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.node_parser import SemanticSplitterNodeParser\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "splitter = SemanticSplitterNodeParser(\n",
    "    buffer_size=1,\n",
    "    breakpoint_percentile_threshold=95,\n",
    "    embed_model=embed_model\n",
    ")\n",
    "\n",
    "chunks = splitter.sentence_splitter(sample_text)\n",
    "print(\"=== 의미 기반 분할 결과 ===\")\n",
    "for i, chunk in enumerate(chunks):\n",
    "    print(f\"Chunk {i + 1}:\", chunk.strip(), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10f7929-12e7-4987-8847-e92cd377c06b",
   "metadata": {},
   "source": [
    "## 2.4 인덱싱"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585e6035-bcf7-4e58-bb88-9c5065cb2f19",
   "metadata": {},
   "source": [
    "### 2.4.2 벡터 저장소 인덱스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80af597e-71c7-4756-90a2-252a926352fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
